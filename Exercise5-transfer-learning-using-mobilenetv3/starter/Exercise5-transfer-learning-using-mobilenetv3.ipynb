{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise: Transfer learning using MobileNetV3\n",
        "\n",
        "In the field of machine learning, transfer learning has emerged as a powerful technique to leverage pre-trained models and apply them to new tasks. This approach allows us to save time and computational resources by reusing the knowledge gained from training on large datasets. In this exercise we use MobileNetV3, a previously state-of-the-art convolutional neural network architecture, to train a classifier for the MNIST dataset using the PyTorch framework.\n",
        "\n",
        "## Steps\n",
        "\n",
        "1. Load the MNIST dataset using the torchvision package.\n",
        "2. Define a PyTorch model using the MobileNetV3 architecture.\n",
        "3. Train the model on the MNIST dataset.\n",
        "4. Evaluate the model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load the MNIST dataset using the torchvision package.\n",
        "\n",
        "The torchvision package provides access to popular datasets, model architectures, and image transformations for computer vision. We can use the torchvision.datasets.MNIST class to load the MNIST dataset. The dataset is downloaded and cached automatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the MNIST dataset using the torchvision package\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Load the training and test datasets using torchvision\n",
        "# Convert to RGB from grayscale by passing in the transform argument and then use the transforms.ToTensor() function\n",
        "\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), lambda x: x.repeat(3, 1, 1)]))\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), lambda x: x.repeat(3, 1, 1)]))\n",
        "\n",
        "# Create a data loader from the training and test datasets\n",
        "# We will convert the images to PyTorch tensors and normalize them\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n",
        "\n",
        "# Print the size of the training and test datasets\n",
        "print('Size of the training dataset:', len(trainset))\n",
        "print('Size of the test dataset:', len(testset))\n",
        "\n",
        "# Print the size of the training and test dataloaders\n",
        "print('Size of the training dataloader:', len(trainloader))\n",
        "print('Size of the test dataloader:', len(testloader))\n",
        "\n",
        "# Print the shape of the first element of the training dataset\n",
        "print('Label of the first element of the training dataset:', trainset[0][1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2. Define a PyTorch model using the MobileNetV3 architecture.\n",
        "\n",
        "The torchvision.models.mobilenet_v3_large class provides a pre-trained MobileNetV3 model. We can use the model as a feature extractor by replacing the last fully-connected layer with a new one that has the correct number of output features for the MNIST dataset. We can then freeze the weights of the convolutional layers and train only the new fully-connected layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "mobilenet_v3_model = models.mobilenet_v3_small(pretrained=True)\n",
        "print(mobilenet_v3_model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(mobilenet_v3_model.classifier[3])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Define a model class that extends the nn.Module class\n",
        "class MobileNetV3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV3, self).__init__()\n",
        "        # Define the MobileNetV3 architecture\n",
        "        self.model = models.mobilenet_v3_small(pretrained=True)\n",
        "        # Replace the last fully-connected layer with a new one\n",
        "        self.model.classifier[3] = nn.Linear(1024, 10)\n",
        "    def forward(self, x):\n",
        "        # Resize the input if needed\n",
        "        if x.shape[-2:] != (224, 224):\n",
        "            x = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def freeze(self):\n",
        "        # Freeze all the weights of the network except for the last fully-connected layer\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.model.classifier[3].parameters():\n",
        "            param.requires_grad = True\n",
        "    def unfreeze(self):\n",
        "        # Unfreeze all the weights of the network\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "# Create an instance of the MobileNetV3 model\n",
        "model = MobileNetV3()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3. Train the model on the MNIST dataset\n",
        "\n",
        "We can train the model using the standard PyTorch training loop. We use the Adam optimizer with a learning rate of 0.001 and a batch size of 64. We train the model for 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set the device as GPU, MPS, or CPU according to availability\n",
        "device = torch.device(\n",
        "    \"cuda:0\" if torch.cuda.is_available() else (\n",
        "        \"mps\" if torch.backends.mps.is_available()\n",
        "        else \"cpu\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a PyTorch training loop\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "model.freeze() # Freeze all the weights except for the last fully-connected layer\n",
        "\n",
        "model = model.to(device) # Move the model weights to the device\n",
        "\n",
        "for epoch in range(5):\n",
        "    for batch_num, (images, labels) in enumerate(trainloader):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        optimizer.zero_grad() \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the loss for every 100th iteration\n",
        "        if (batch_num) % 500 == 0:\n",
        "            print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, 10, batch_num+1, len(trainloader), loss.item()))\n",
        "                \n",
        "    # Print the loss and accuracy on the test set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            # Move tensors to the configured device\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss += criterion(outputs, labels)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Compute the accuracy\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "    print('Test Loss of the model on the test images: {} %'.format(loss / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4. Evaluate the model on the test set\n",
        "\n",
        "We evaluate the model on the test set by:\n",
        "* printing the accuracy,\n",
        "* plotting a confusion matrix to visualize the performance of the classifier, and\n",
        "* plotting a few examples of correct and incorrect predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Print the accuracy on the test set\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss += criterion(outputs, labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Compute the accuracy\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "print('Test Loss of the model on the test images: {:0.3f}'.format(loss / total))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot a confusion matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Get predictions for the test data and convert them to a NumPy array\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Append batch prediction results\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "# Plot the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plotting a few examples of correct and incorrect predictions\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Get predictions for the test data and convert them to a NumPy array\n",
        "y_pred = []\n",
        "y_true = []\n",
        "images = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for image, label in testloader:\n",
        "        # Move tensors to the configured device\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        # Append batch prediction results\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_true.extend(label.cpu().numpy())\n",
        "        images.extend(image.cpu().numpy())\n",
        "\n",
        "# Plot a few examples of correct and incorrect predictions\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i, (image, y_t, y_p) in enumerate(zip(images, y_true, y_pred)):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.axis('off')\n",
        "    image = np.transpose(image, (1, 2, 0))  # Convert the image from 3x28x28 to 28x28x3\n",
        "    plt.imshow(np.squeeze(image))\n",
        "    if y_t == y_p:\n",
        "        plt.title(y_p)\n",
        "    else:\n",
        "        plt.title(y_p, color='red')\n",
        "        \n",
        "    if i == 24:\n",
        "        plt.show()\n",
        "        break\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
