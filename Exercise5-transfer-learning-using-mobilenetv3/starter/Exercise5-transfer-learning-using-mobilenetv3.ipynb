{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise: Transfer learning using MobileNetV3\n",
        "\n",
        "In the field of machine learning, transfer learning is a powerful technique that leverages pre-trained models and applies them to new tasks. This approach allows us to save time and computational resources by reusing the knowledge gained from training on large datasets.\n",
        "\n",
        "In this exercise we use MobileNetV3, a convolutional neural network architecture for mobile devices, to train a classifier for the Fashion-MNIST dataset using the PyTorch framework.\n",
        "\n",
        "Fashion-MNIST is a drop-in replacement for MNIST (images of size 28x28 with 10 classes) but instead of hand-written digits it contains tiny images of clothes!\n",
        "\n",
        "## Steps\n",
        "\n",
        "1. Load the Fashion-MNIST dataset using the torchvision package.\n",
        "2. Define a PyTorch model using the MobileNetV3 architecture.\n",
        "3. Train the model on the Fashion-MNIST dataset.\n",
        "4. Evaluate the model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load the Fashion-MNIST dataset\n",
        "\n",
        "The torchvision package provides access to popular datasets, model architectures, and image transformations for computer vision.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Fashion-MNIST dataset\n",
        "\n",
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "def load_data(batch_size, data_dir=\"data\"):\n",
        "    \"\"\"Load the Fashion-MNIST dataset.\"\"\"\n",
        "\n",
        "    # Define transforms to normalize the data\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        "    )\n",
        "\n",
        "    # Download and load the training data\n",
        "    trainset = datasets.FashionMNIST(\n",
        "        data_dir, download=True, train=True, transform=transform\n",
        "    )\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    # Download and load the test data\n",
        "    testset = datasets.FashionMNIST(\n",
        "        data_dir, download=True, train=False, transform=transform\n",
        "    )\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "trainloader, testloader = load_data(64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sometimes it's useful to create functions that will help us work with the labels when they're a little more complicated than the handwritten digits 0-9. Let's create those now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define some helper functions to helps with the labels\n",
        "def get_class_names():\n",
        "    \"\"\"Return the list of classes in the Fashion-MNIST dataset.\"\"\"\n",
        "    return [\n",
        "        \"T-shirt/top\",\n",
        "        \"Trouser\",\n",
        "        \"Pullover\",\n",
        "        \"Dress\",\n",
        "        \"Coat\",\n",
        "        \"Sandal\",\n",
        "        \"Shirt\",\n",
        "        \"Sneaker\",\n",
        "        \"Bag\",\n",
        "        \"Ankle boot\",\n",
        "    ]\n",
        "\n",
        "\n",
        "def get_class_name(class_index):\n",
        "    \"\"\"Return the class name for the given index.\"\"\"\n",
        "    return get_class_names()[class_index]\n",
        "\n",
        "\n",
        "def get_class_index(class_name):\n",
        "    \"\"\"Return the class index for the given name.\"\"\"\n",
        "    return get_class_names().index(class_name)\n",
        "\n",
        "\n",
        "for class_index in range(10):\n",
        "    print(f\"class_index={class_index}, class_name={get_class_name(class_index)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's always good to inspect your data before you use it to train a model just to know everything is fine. You know what they say: garbage in, garbage out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show 10 images from the training set with their labels\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# function to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()  # convert from tensor to numpy array\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # transpose dimensions\n",
        "\n",
        "\n",
        "images, labels = next(iter(trainloader))  # get the first batch\n",
        "\n",
        "# show images with labels\n",
        "fig = plt.figure(figsize=(15, 4))\n",
        "plot_size = 10\n",
        "\n",
        "for idx in np.arange(plot_size):\n",
        "    ax = fig.add_subplot(2, plot_size // 2, idx + 1, xticks=[], yticks=[])\n",
        "    imshow(images[idx])\n",
        "    ax.set_title(get_class_name(int(labels[idx])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2. Define a PyTorch model using the MobileNetV3 architecture.\n",
        "\n",
        "The `torchvision.models.mobilenet_v3_large` class provides access to pre-trained MobileNetV3 model. We can use the model and replace the final layer with a fully-connected layer with 10 outputs since we have 10 classes. We can then freeze the weights of the convolutional layers and train only the new fully-connected layer.\n",
        "\n",
        "Let's start with inspecting the original MobileNetV3 (small version) first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a pre-trained MobileNetV3 and inspect its structure\n",
        "import torchvision.models as models\n",
        "\n",
        "mobilenet_v3_model = models.mobilenet_v3_small(pretrained=True)\n",
        "print(mobilenet_v3_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take note of the `classifier` section of the model.\n",
        "\n",
        "```\n",
        "  (classifier): Sequential(\n",
        "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
        "    (1): Hardswish()\n",
        "    (2): Dropout(p=0.2, inplace=True)\n",
        "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
        "  )\n",
        "```\n",
        "\n",
        "There are 1000 output features, but our dataset does not have that many. See if you can complete the next cell so that it has the right number of output nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace <MASK> to complete this code cell\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# Define a model class that extends the nn.Module class\n",
        "class MobileNetV3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV3, self).__init__()\n",
        "\n",
        "        # Load the pre-trained MobileNetV3 (Small) architecture\n",
        "        self.model = <MASK>\n",
        "\n",
        "        # Replace the last fully-connected layer with a new one of the right size\n",
        "        self.model.classifier[3] = <MASK>\n",
        "\n",
        "        # Freeze all the weights of the network except for the last fully-connected layer\n",
        "        self.freeze()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convert 1x28x28 input tensor to 3x28x28 tensor, to convert it to a color image\n",
        "        x = x.repeat(1, 3, 1, 1)\n",
        "\n",
        "        # Resize the input to 224x224, since MobileNetV3 (Small) expects images of that size\n",
        "        if x.shape[2:] != (224, 224):\n",
        "            x = F.interpolate(x, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "        # Forward pass\n",
        "        return self.model(x)\n",
        "\n",
        "    def freeze(self):\n",
        "        # Freeze all the weights of the network except for the last fully-connected layer\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze the final layer\n",
        "        for param in self.model.classifier[3].parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def unfreeze(self):\n",
        "        # Unfreeze all the weights of the network\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "\n",
        "# Create an instance of the MobileNetV3 model\n",
        "model = MobileNetV3()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3. Train the model on the MNIST dataset\n",
        "\n",
        "We can train the model using the standard PyTorch training loop. For the loss function, we'll use CrossEntropyLoss. We also use the Adam optimizer with a learning rate of 0.002. We train the model for 1 epoch so we can see how the model performs after just one pass of the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace <MASK> to complete this code cell\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "\n",
        "loss_fn = <MASK>\n",
        "\n",
        "optimizer = <MASK>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's choose our device automatically (CPU, GPU, or MPS) and write our training loop!\n",
        "\n",
        "The MPS backend is for M1/M2/etc Macs.\n",
        "\n",
        "If you are having any errors running the code locally, you should try to use the `cpu` mode manually, i.e. `device = torch.device(\"cpu\")`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the device as GPU, MPS, or CPU according to availability\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace <MASK> to complete this code cell\n",
        "\n",
        "# Create a PyTorch training loop\n",
        "\n",
        "model = model.to(device)  # Move the model weights to the device\n",
        "\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    for batch_num, (images, labels) in enumerate(trainloader):\n",
        "        # Move tensors to the device\n",
        "        images = images<MASK>\n",
        "        labels = labels<MASK>\n",
        "\n",
        "        # Zero out the optimizer's gradient buffer\n",
        "        <MASK>\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = <MASK>\n",
        "\n",
        "        # Calculate the loss and perform backprop\n",
        "        loss = <MASK>\n",
        "        <MASK>\n",
        "\n",
        "        # Update the weights\n",
        "        <MASK>\n",
        "\n",
        "        # Print the loss for every 100th iteration\n",
        "        if (batch_num) % 100 == 0:\n",
        "            print(\n",
        "                \"Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}\".format(\n",
        "                    epoch + 1, epochs, batch_num + 1, len(trainloader), loss.item()\n",
        "                )\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4. Evaluate the model on the test set\n",
        "\n",
        "We evaluate the model on the test set by:\n",
        "* printing the accuracy\n",
        "* plotting a few examples of correct and incorrect predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace <MASK> to complete this code cell\n",
        "\n",
        "# Print the loss and accuracy on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "loss = 0\n",
        "\n",
        "for images, labels in testloader:\n",
        "    # Move tensors to the configured device\n",
        "    <MASK>\n",
        "    <MASK>\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = <MASK>\n",
        "    loss += <MASK>\n",
        "\n",
        "    # torch.max return both max and argmax. We get the argmax here.\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Compute the accuracy\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\n",
        "    \"Test Accuracy of the model on the test images: {} %\".format(100 * correct / total)\n",
        ")\n",
        "print(\"Test Loss of the model on the test images: {}\".format(loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting a few examples of correct and incorrect predictions\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get the first batch of images and labels\n",
        "images, labels = next(iter(testloader))\n",
        "\n",
        "# Move tensors to the configured device\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# Forward pass\n",
        "outputs = model(images)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "# Plot the images with labels, at most 10\n",
        "fig = plt.figure(figsize=(15, 4))\n",
        "\n",
        "for idx in np.arange(min(10, len(images))):\n",
        "    ax = fig.add_subplot(2, 10 // 2, idx + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images.cpu()[idx]))\n",
        "    ax.set_title(\n",
        "        \"{} ({})\".format(get_class_name(predicted[idx]), get_class_name(labels[idx])),\n",
        "        color=(\"green\" if predicted[idx] == labels[idx] else \"red\"),\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
