{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise: PyTorch and HuggingFace scavenger hunt!\n",
        "\n",
        "In the world of artificial intelligence, PyTorch and HuggingFace have emerged as powerful tools for developing and deploying neural networks. PyTorch, a popular open-source machine learning library, provides a flexible and efficient platform for developing and training models. HuggingFace, on the other hand, offers a comprehensive set of datasets and pre-trained models, making it easier for developers to learn from and contribute to the community. In this scavenger hunt, we will explore the capabilities of PyTorch and HuggingFace, uncovering hidden treasures on the way."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Familiarize yourself with PyTorch\n",
        "\n",
        "Learn the basics of PyTorch, including tensors, neural net parts, loss functions, and optimizers. This will provide a foundation for understanding and utilizing its capabilities in developing and training neural networks."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To install PyTorch, you can use pip\n",
        "\n",
        "! pip3 install -q torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyTorch tensors\n",
        "\n",
        "Examine the PyTorch tensors documentation [here](https://pytorch.org/docs/stable/tensors.html).\n",
        "\n",
        "In the following cell, create a tensor named `my_tensor` of size 3x3 with values of your choice. The tensor should be created on the GPU if available. Print the tensor."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hint: Use torch.cuda.is_available() to check if GPU is available\n",
        "\n",
        "import torch\n",
        "\n",
        "# Set the device to be used for the tensor\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create a tensor on the appropriate device\n",
        "my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], device=device)\n",
        "\n",
        "# Print the tensor\n",
        "print(my_tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the previous cell\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    assert my_tensor.device.type == 'cuda'\n",
        "else:\n",
        "    assert my_tensor.device.type == 'cpu'\n",
        "\n",
        "assert my_tensor.shape == (3, 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neural Net Constructor Kit `torch.nn`\n",
        "\n",
        "You can think of the `torch.nn` ([documentation](https://pytorch.org/docs/stable/nn.html)) module as a constructor kit for neural networks. It provides the building blocks for creating neural networks, including layers, activation functions, loss functions, and more. The `torch.nn.functional` ([documentation](https://pytorch.org/docs/stable/nn.functional.html)) module contains useful functions for building neural networks, such as activation functions and loss functions.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Create a three layer Multi-Layer Perceptron (MLP) neural network with the following specifications:\n",
        "\n",
        "- Input layer: 784 neurons\n",
        "- Hidden layer: 128 neurons\n",
        "- Output layer: 10 neurons\n",
        "\n",
        "Use the ReLU activation function for the hidden layer and the softmax activation function for the output layer. Print the neural network."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyMLP(nn.Module):\n",
        "    \"\"\"My Multilayer Perceptron (MLP)\n",
        "\n",
        "    Specifications:\n",
        "\n",
        "        - Input layer: 784 neurons\n",
        "        - Hidden layer: 128 neurons with ReLU activation\n",
        "        - Output layer: 10 neurons with softmax activation\n",
        "   \n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MyMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.softmax(self.fc2(x))\n",
        "        return x\n",
        "    \n",
        "my_mlp = MyMLP()\n",
        "print(my_mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check your work here:\n",
        "\n",
        "\n",
        "# Check the number of inputs\n",
        "assert my_mlp.fc1.in_features == 784\n",
        "\n",
        "# Check the number of outputs\n",
        "assert my_mlp.fc2.out_features == 10\n",
        "\n",
        "# Check the number of nodes in the hidden layer\n",
        "assert my_mlp.fc1.out_features == 128\n",
        "\n",
        "# Check that my_mlp.fc1 is a fully connected layer\n",
        "assert isinstance(my_mlp.fc1, nn.Linear)\n",
        "\n",
        "# Check that my_mlp.fc2 is a fully connected layer\n",
        "assert isinstance(my_mlp.fc2, nn.Linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyTorch Loss Functions, Optimizers, and training loops\n",
        "\n",
        "PyTorch comes with a number of built-in loss functions and optimizers that can be used to train neural networks. The loss functions are implemented in the `torch.nn` ([documentation](https://pytorch.org/docs/stable/nn.html#loss-functions)) module, while the optimizers are implemented in the `torch.optim` ([documentation](https://pytorch.org/docs/stable/optim.html)) module.\n",
        "\n",
        "\n",
        "Instructions:\n",
        "\n",
        "- Create a loss function using the `torch.nn.CrossEntropyLoss` ([documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)) class.\n",
        "- Create an optimizer using the `torch.optim.SGD` ([documentation](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)) class with a learning rate of 0.001.\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Loss function (by convention we use the variable criterion)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer (by convention we use the variable optimizer)\n",
        "optimizer = torch.optim.SGD(my_mlp.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check\n",
        "\n",
        "assert isinstance(criterion, nn.CrossEntropyLoss), \"criterion should be an instance of CrossEntropyLoss\"\n",
        "assert isinstance(optimizer, torch.optim.SGD), \"optimizer should be an instance of SGD\"\n",
        "assert optimizer.defaults['lr'] == 0.01, \"learning rate should be 0.01\"\n",
        "assert optimizer.param_groups[0]['params'] == list(my_mlp.parameters()), \"optimizer should be passed the MLP parameters\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a training loop\n",
        "for epoch in range(100):\n",
        "    # Generate some random inputs and outputs\n",
        "    x = torch.randn(64, 784)\n",
        "    y = torch.randint(0, 10, (64,))\n",
        "\n",
        "    # Forward pass\n",
        "    y_pred = my_mlp(x)\n",
        "\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred, y)\n",
        "\n",
        "    # Zero gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch: {epoch}, Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check\n",
        "\n",
        "assert abs(loss.item() - 2.3) < 0.1, \"loss should be around 2.3\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get to know HuggingFace\n",
        "\n",
        "HuggingFace is a popular destination for pre-trained models and datasets that can be applied to a variety of tasks quickly and easily. In this section, we will explore the capabilities of HuggingFace and learn how to use it to build and train neural networks."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To install HuggingFace Transformers, you can use pip\n",
        "\n",
        "! pip3 install transformers datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download a model from HuggingFace and use it for sentiment analysis\n",
        "\n",
        "HuggingFace provides a number of pre-trained models that can be used for a variety of tasks. In this exercise, we will use the `distilbert-base-uncased-finetuned-sst-2-english` model to perform sentiment analysis on a movie review.\n",
        "\n",
        "Instructions:\n",
        "- Instantiate an AutoModelForSequenceClassification model ([documentation](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodelforsequenceclassification)) using the `distilbert-base-uncased-finetuned-sst-2-english` model.\n",
        "- Instantiate an AutoTokenizer ([documentation](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#autotokenizer)) using the `distilbert-base-uncased-finetuned-sst-2-english` model."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the model and tokenizer\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
        "\n",
        "def get_prediction(review):\n",
        "    \"\"\"Given a review, return the predicted sentiment\"\"\"\n",
        "\n",
        "    # Tokenize the review\n",
        "    inputs = tokenizer(review, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform the prediction\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Get the predicted class\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "    return \"positive\" if predictions.item() == 1 else \"negative\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Check\n",
        "\n",
        "review = \"This movie is not so great :(\"\n",
        "\n",
        "print(f'Review: {review}')\n",
        "print(f'Sentiment: {get_prediction(review)}')\n",
        "\n",
        "assert get_prediction(review) == 'negative', \"The prediction should be negative\"\n",
        "\n",
        "\n",
        "review = \"This movie rocks!\"\n",
        "\n",
        "print(f'Review: {review}')\n",
        "print(f'Sentiment: {get_prediction(review)}')\n",
        "\n",
        "assert get_prediction(review) == 'positive', \"The prediction should be positive\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download a dataset from HuggingFace and inspect it\n",
        "\n",
        "HuggingFace provides a number of datasets that can be used for a variety of tasks. In this exercise, we will use the `imdb` dataset and pass it to the model we instantiated in the previous exercise."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset('imdb', split='test', cache_dir='data/imdb/')\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the first 3 reviews\n",
        "reviews = dataset['text'][:3]\n",
        "\n",
        "# Get the first 3 labels\n",
        "labels = dataset['label'][:3]\n",
        "\n",
        "# Check\n",
        "for review, label in zip(reviews, labels):\n",
        "    print(f'Review: {review[:80]} \\n... {review[-80:]}')\n",
        "    print(f'Label: {\"positive\" if label else \"negative\"}')\n",
        "    print(f'Prediction: {get_prediction(review)}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the last 3 reviews\n",
        "reviews = dataset['text'][-3:]\n",
        "\n",
        "# Get the last 3 labels\n",
        "labels = dataset['label'][-3:]\n",
        "\n",
        "# Check\n",
        "for review, label in zip(reviews, labels):\n",
        "    print(f'Review: {review[:80]} \\n... {review[-80:]}')\n",
        "    print(f'Label: {\"positive\" if label else \"negative\"}')\n",
        "    print(f'Prediction: {get_prediction(review)}\\n')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
