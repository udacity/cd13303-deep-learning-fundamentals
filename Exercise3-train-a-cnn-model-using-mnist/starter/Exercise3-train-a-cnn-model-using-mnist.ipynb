{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise: Train a CNN model using MNIST data\n",
        "\n",
        "Convolutional Neural Networks (CNNs) are a powerful tool for image classification tasks. In this exercise, we will explore the process of training a CNN model using the MNIST dataset, a widely-used benchmark dataset for handwritten digit recognition. To accomplish this, we will use PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install needed packages if not already installed\n",
        "\n",
        "! pip install -q torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import packages for the entire notebook\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Various helper functions\n",
        "\n",
        "def imshow(img, size=3):\n",
        "    \"\"\"Display an image in the notebook\"\"\"\n",
        "    img = img / 2 + 0.5  # unnormalize the image\n",
        "    npimg = img.numpy()  # convert to numpy array\n",
        "    plt.figure(figsize=(size, size))  # specific the figure size\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap=\"gray\")  # transpose the array\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and preprocess the MNIST dataset\n",
        "\n",
        "Use the torchvision library to load the MNIST dataset. Preprocess the dataset by applying any necessary transformations, such as normalization or resizing, to prepare the data for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the MNIST dataset\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Set batch size\n",
        "bs = 64\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=bs, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=bs, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show the classes of the dataset\n",
        "for class_name in trainset.classes:\n",
        "    print(class_name)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show some examples with the labels\n",
        "\n",
        "# Get some random training images\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "\n",
        "# Print labels\n",
        "print(\", \".join(trainset.classes[labels[j]] for j in range(min(4, bs))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the CNN model architecture\n",
        "\n",
        "Create a CNN model architecture using PyTorch's nn.Module class. Define the layers, activation functions, and any other components required for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the CNN\n",
        "\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            1, 6, 5\n",
        "        )  # 1 input channel, 6 output channels, 5x5 kernel\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 2x2 kernel, stride 2\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            6, 16, 5\n",
        "        )  # 6 input channels, 16 output channels, 5x5 kernel\n",
        "        self.fc1 = nn.Linear(\n",
        "            16 * 4 * 4, 120\n",
        "        )  # 16*4*4 input features, 120 output features\n",
        "        self.fc2 = nn.Linear(120, 84)  # 120 input features, 84 output features\n",
        "        self.fc3 = nn.Linear(84, 10)  # 84 input features, 10 output features\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(\n",
        "            F.relu(self.conv1(x))\n",
        "        )  # Convolutional layer 1, followed by ReLU and pooling\n",
        "        x = self.pool(\n",
        "            F.relu(self.conv2(x))\n",
        "        )  # Convolutional layer 2, followed by ReLU and pooling\n",
        "        x = x.view(-1, 16 * 4 * 4)  # Reshape to 16*4*4 features\n",
        "        x = F.relu(self.fc1(x))  # Fully connected layer 1, followed by ReLU\n",
        "        x = F.relu(self.fc2(x))  # Fully connected layer 2, followed by ReLU\n",
        "        x = self.fc3(x)  # Fully connected layer 3\n",
        "        return x\n",
        "\n",
        "\n",
        "my_cnn = MyCNN()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the loss function and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(my_cnn.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the CNN model\n",
        "\n",
        "Use the prepared dataset and the defined model to train the CNN. This involves iterating over the dataset, passing the input images through the model, calculating the loss, and updating the model's parameters using backpropagation and gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Specify the device to train on\n",
        "\n",
        "# We will use a GPU if available, otherwise we will use the CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define a training loop\n",
        "my_cnn.to(device)  # move the model to the device\n",
        "\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader):  # trainloader contains the training data\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # move the data to the device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()  # set the gradients to zero\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = my_cnn(inputs)  # compute the output\n",
        "        loss = criterion(outputs, labels)  # compute the loss\n",
        "        loss.backward()  # compute the gradients\n",
        "        optimizer.step()  # update the weights\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % (200) == 199:  # print every 200 batches\n",
        "            print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the trained model\n",
        "\n",
        "After training, evaluate the performance of the trained CNN model on a separate test dataset. Calculate metrics such as accuracy, precision, and recall to assess the model's performance in classifying handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show the loss and accuracy on the test set\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "loss = 0\n",
        "with torch.no_grad():  # we don't need to compute the gradients here\n",
        "    for data in testloader:  # testloader contains the test data\n",
        "        images, labels = data\n",
        "\n",
        "        # move the data to the device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = my_cnn(images)  # compute the output\n",
        "        _, predicted = torch.max(outputs.data, 1)  # get the predicted class\n",
        "\n",
        "        total += labels.size(0)  # add the number of labels\n",
        "        correct += (\n",
        "            (predicted == labels).sum().item()\n",
        "        )  # add the number of correct predictions\n",
        "\n",
        "        loss += criterion(outputs, labels).item()  # add the loss\n",
        "\n",
        "print(\"Accuracy of the network on the test images: %d %%\" % (100 * correct / total))\n",
        "print(\"Average loss: %.3f\" % (loss / total))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show the confusion matrix on the test dataset\n",
        "\n",
        "\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():  # we don't need to compute the gradients here\n",
        "    for data in testloader:  # testloader contains the test data\n",
        "        images, labels = data\n",
        "\n",
        "        # move the data to the device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = my_cnn(images)  # compute the output\n",
        "        _, predicted = torch.max(outputs.data, 1)  # get the predicted class\n",
        "\n",
        "        y_true += labels.tolist()\n",
        "        y_pred += predicted.tolist()\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(\n",
        "    cm, index=[i for i in trainset.classes], columns=[i for i in trainset.classes]\n",
        ")\n",
        "plt.figure(figsize=(10, 7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show 25 random images and their predicted labels\n",
        "\n",
        "\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize the image\n",
        "    npimg = img.numpy()  # convert to numpy array\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # transpose the array\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random test images\n",
        "images, labels = next(iter(testloader))\n",
        "\n",
        "# move the data to the device\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# print labels\n",
        "print(\n",
        "    \"GroundTruth: \", \", \".join(\"%5s\" % trainset.classes[labels[j]] for j in range(bs))\n",
        ")\n",
        "\n",
        "# compute the outputs\n",
        "outputs = my_cnn(images)\n",
        "\n",
        "# get the predicted classes\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# print predicted labels\n",
        "print(\n",
        "    \"Predicted: \", \", \".join(\"%5s\" % trainset.classes[predicted[j]] for j in range(bs))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show the first 10 misclassified images\n",
        "\n",
        "\n",
        "misclassified_num = 0\n",
        "\n",
        "# iterate through all the test images one-by-one\n",
        "single_testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=1, shuffle=False, num_workers=1\n",
        ")\n",
        "for images, labels in single_testloader:\n",
        "    # move the data to the device\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # compute the outputs\n",
        "    outputs = my_cnn(images)\n",
        "\n",
        "    # get the predicted classes\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # get the indices of the misclassified images\n",
        "    misclassified = (predicted != labels).nonzero()[:, 0]\n",
        "\n",
        "    # if there are no misclassified images, continue\n",
        "    if len(misclassified) > 0:\n",
        "        misclassified_num += 1\n",
        "\n",
        "        # show the misclassified images\n",
        "        imshow(torchvision.utils.make_grid(images[misclassified]), size=1.5)\n",
        "\n",
        "        index = misclassified.item()\n",
        "        print('Predicted: ', trainset.classes[predicted[index]], ', Ground truth: ', trainset.classes[labels[index]])\n",
        "\n",
        "    if misclassified_num >= 5:\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
